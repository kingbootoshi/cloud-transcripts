# Deployment Guide

This guide covers deploying Cloud Transcripts to production environments.

## Overview

The application consists of several components that can be deployed independently:

1. **Next.js Web App** → Vercel/Railway/AWS
2. **Modal Worker** → Modal Platform
3. **Database** → Supabase Cloud
4. **File Storage** → AWS S3

## Prerequisites

- Domain name with DNS control
- SSL certificate (auto-generated by most platforms)
- Production accounts for all services
- GitHub repository (for CI/CD)

## Component Deployment

### 1. Database (Supabase)

#### Create Production Project

1. Go to [app.supabase.com](https://app.supabase.com)
2. Create new project with strong database password
3. Select appropriate region (closest to users)
4. Wait for project provisioning

#### Configure Database

1. Run migrations:
   ```bash
   supabase link --project-ref your-project-ref
   supabase db push
   ```

2. Enable real-time for tables:
   - Go to Database → Replication
   - Enable replication for `videos` table
   - Enable replication for `transcripts` table

3. Configure connection pooling:
   - Go to Settings → Database
   - Note connection pooling URL
   - Use for serverless environments

### 2. File Storage (AWS S3)

#### Create Production Bucket

1. Create S3 bucket:
   ```bash
   aws s3 mb s3://your-production-bucket
   ```

2. Configure bucket policy:
   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Sid": "AllowCloudTranscripts",
         "Effect": "Allow",
         "Principal": {
           "AWS": "arn:aws:iam::YOUR_ACCOUNT:user/cloud-transcripts-prod"
         },
         "Action": ["s3:PutObject", "s3:GetObject"],
         "Resource": "arn:aws:s3:::your-production-bucket/*"
       }
     ]
   }
   ```

3. Configure CORS:
   ```json
   [
     {
       "AllowedHeaders": ["*"],
       "AllowedMethods": ["PUT", "POST", "GET", "HEAD"],
       "AllowedOrigins": ["https://your-domain.com"],
       "ExposeHeaders": ["ETag"],
       "MaxAgeSeconds": 3000
     }
   ]
   ```

4. Enable versioning and lifecycle rules:
   ```bash
   aws s3api put-bucket-versioning \
     --bucket your-production-bucket \
     --versioning-configuration Status=Enabled
   ```

### 3. Modal Worker

#### Deploy to Production

1. Create production secrets in Modal:
   ```bash
   modal secret create transcript-worker-prod \
     AWS_ACCESS_KEY_ID=xxx \
     AWS_SECRET_ACCESS_KEY=xxx \
     AWS_DEFAULT_REGION=us-east-1 \
     HF_TOKEN=xxx \
     WEBHOOK_SECRET=xxx \
     WEBHOOK_URL=https://your-domain.com/api/webhook/modal
   ```

2. Update `main.py` to use production secret:
   ```python
   @app.function(
     secrets=[modal.Secret.from_name("transcript-worker-prod")]
   )
   ```

3. Deploy with production tag:
   ```bash
   modal deploy apps/worker/main.py --tag production
   ```

4. Note the production endpoint URL

### 4. Next.js Application

#### Option A: Deploy to Vercel

1. Connect GitHub repository to Vercel
2. Configure environment variables:
   ```
   NEXT_PUBLIC_SUPABASE_URL=xxx
   NEXT_PUBLIC_SUPABASE_ANON_KEY=xxx
   SUPABASE_SERVICE_KEY=xxx
   AWS_ACCESS_KEY_ID=xxx
   AWS_SECRET_ACCESS_KEY=xxx
   AWS_REGION=us-east-1
   S3_BUCKET=your-production-bucket
   MODAL_TOKEN=xxx
   MODAL_QUEUE_URL=xxx
   WEBHOOK_SECRET=xxx
   WEBHOOK_URL=https://your-domain.com/api/webhook/modal
   ```

3. Configure build settings:
   - Framework: Next.js
   - Build command: `npm run build`
   - Output directory: `.next`

4. Deploy:
   ```bash
   vercel --prod
   ```

#### Option B: Deploy to Railway

1. Create new Railway project
2. Add GitHub repo
3. Configure environment variables (same as above)
4. Deploy with:
   ```bash
   railway up
   ```

#### Option C: Deploy to AWS (EC2/ECS)

1. Build Docker image:
   ```dockerfile
   # Dockerfile
   FROM node:18-alpine AS deps
   WORKDIR /app
   COPY package*.json ./
   RUN npm ci --only=production
   
   FROM node:18-alpine AS builder
   WORKDIR /app
   COPY --from=deps /app/node_modules ./node_modules
   COPY . .
   RUN npm run build
   
   FROM node:18-alpine AS runner
   WORKDIR /app
   ENV NODE_ENV production
   COPY --from=builder /app/public ./public
   COPY --from=builder /app/.next/standalone ./
   COPY --from=builder /app/.next/static ./.next/static
   
   EXPOSE 3000
   CMD ["node", "server.js"]
   ```

2. Push to ECR:
   ```bash
   aws ecr get-login-password | docker login --username AWS --password-stdin $ECR_URI
   docker build -t cloud-transcripts .
   docker tag cloud-transcripts:latest $ECR_URI/cloud-transcripts:latest
   docker push $ECR_URI/cloud-transcripts:latest
   ```

3. Deploy to ECS or EC2

## Environment Configuration

### Production Environment Variables

Create `.env.production`:

```bash
# Public variables (exposed to browser)
NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=xxx

# Server-only variables
SUPABASE_SERVICE_KEY=xxx
AWS_ACCESS_KEY_ID=xxx
AWS_SECRET_ACCESS_KEY=xxx
AWS_REGION=us-east-1
S3_BUCKET=production-bucket
MODAL_TOKEN=xxx
MODAL_QUEUE_URL=https://xxx.modal.run
WEBHOOK_SECRET=xxx
WEBHOOK_URL=https://your-domain.com/api/webhook/modal

# Optional
SENTRY_DSN=xxx
LOG_LEVEL=info
NODE_ENV=production
```

### Security Hardening

1. **API Keys Rotation**:
   ```bash
   # Rotate Supabase service key
   # Rotate AWS access keys
   # Update Modal secrets
   ```

2. **Network Security**:
   - Use VPC for AWS resources
   - Configure security groups
   - Enable AWS WAF for DDoS protection

3. **HTTPS Only**:
   - Force SSL in Supabase
   - Redirect HTTP to HTTPS
   - Use HSTS headers

## CI/CD Pipeline

### GitHub Actions

Create `.github/workflows/deploy.yml`:

```yaml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: 18
          cache: 'npm'
      - run: npm ci
      - run: npm run test
      - run: npm run lint

  deploy-worker:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - run: pip install modal
      - run: modal token set --token-id ${{ secrets.MODAL_TOKEN }}
      - run: modal deploy apps/worker/main.py --tag production

  deploy-web:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          vercel-args: '--prod'
```

## Monitoring & Observability

### 1. Application Monitoring

#### Sentry Integration

1. Install Sentry:
   ```bash
   npm install @sentry/nextjs
   ```

2. Configure `sentry.client.config.js`:
   ```javascript
   import * as Sentry from "@sentry/nextjs";
   
   Sentry.init({
     dsn: process.env.SENTRY_DSN,
     environment: process.env.NODE_ENV,
     tracesSampleRate: 0.1,
   });
   ```

3. Add to environment variables

#### Custom Metrics

Track key metrics:
- Upload success rate
- Transcription completion time
- API response times
- Error rates by type

### 2. Infrastructure Monitoring

#### AWS CloudWatch

1. Enable S3 bucket metrics
2. Set up CloudWatch alarms:
   - High error rate
   - S3 bucket size
   - API Gateway 4xx/5xx errors

#### Modal Dashboard

Monitor worker performance:
- GPU utilization
- Job completion times
- Error logs
- Cost tracking

#### Supabase Dashboard

Track database metrics:
- Query performance
- Connection count
- Storage usage
- Real-time subscriptions

### 3. Uptime Monitoring

Use services like:
- Pingdom
- UptimeRobot
- Better Uptime

Monitor endpoints:
- `/` - Homepage
- `/api/trpc/health` - API health
- Modal worker endpoint

## Scaling Considerations

### Horizontal Scaling

1. **Web Application**:
   - Use CDN for static assets
   - Deploy to multiple regions
   - Use edge functions for API

2. **Modal Workers**:
   - Automatic scaling by Modal
   - Configure concurrency limits
   - Use appropriate GPU types

3. **Database**:
   - Supabase handles scaling
   - Monitor connection limits
   - Use read replicas if needed

### Performance Optimization

1. **Caching**:
   ```typescript
   // Add Redis for caching
   import Redis from 'ioredis'
   const redis = new Redis(process.env.REDIS_URL)
   
   // Cache presigned URLs
   const cached = await redis.get(`url:${key}`)
   if (cached) return JSON.parse(cached)
   ```

2. **CDN Configuration**:
   - CloudFront for S3 files
   - Vercel Edge Network
   - Cache headers optimization

3. **Database Optimization**:
   - Analyze slow queries
   - Add appropriate indexes
   - Use connection pooling

## Backup & Disaster Recovery

### Automated Backups

1. **Database**:
   - Supabase daily backups
   - Enable point-in-time recovery
   - Test restore procedures

2. **S3 Files**:
   - Enable versioning
   - Cross-region replication
   - Lifecycle policies for old files

3. **Code & Configuration**:
   - Git for version control
   - Infrastructure as Code
   - Document all configurations

### Disaster Recovery Plan

1. **RTO/RPO Targets**:
   - Recovery Time Objective: 4 hours
   - Recovery Point Objective: 1 hour

2. **Runbooks**:
   - Database restore procedure
   - S3 bucket recovery
   - DNS failover process

3. **Regular Testing**:
   - Monthly backup tests
   - Quarterly DR drills
   - Update documentation

## Cost Optimization

### Monitor Costs

1. **AWS Cost Explorer**:
   - S3 storage and transfer
   - CloudWatch logs
   - Data transfer costs

2. **Modal Usage**:
   - GPU hours used
   - Optimize model selection
   - Batch processing

3. **Supabase Billing**:
   - Database size
   - Bandwidth usage
   - Connection hours

### Optimization Strategies

1. **S3 Lifecycle Rules**:
   ```json
   {
     "Rules": [{
       "Id": "archive-old-transcripts",
       "Status": "Enabled",
       "Transitions": [{
         "Days": 90,
         "StorageClass": "GLACIER"
       }]
     }]
   }
   ```

2. **Reserved Capacity**:
   - AWS Reserved Instances
   - Supabase Pro plan
   - Modal committed usage

3. **Caching Strategy**:
   - Cache common operations
   - Use CDN effectively
   - Minimize API calls

## Security Checklist

- [ ] All secrets in environment variables
- [ ] HTTPS enforced everywhere
- [ ] API rate limiting enabled
- [ ] AWS IAM least privilege
- [ ] Regular security updates
- [ ] Dependency vulnerability scanning
- [ ] OWASP Top 10 compliance
- [ ] Data encryption at rest
- [ ] Secure webhook signatures
- [ ] Regular penetration testing

## Post-Deployment

1. **Smoke Tests**:
   - Upload test file
   - Verify transcription
   - Check webhook delivery
   - Test download links

2. **Performance Baseline**:
   - Measure API response times
   - Document normal GPU usage
   - Set alerting thresholds

3. **Documentation**:
   - Update deployment notes
   - Document any issues
   - Create operation runbooks 